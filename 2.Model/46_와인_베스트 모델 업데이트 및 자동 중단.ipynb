{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베스트 모델 만들기 - 와인 사례\n",
    "## 이진 분류\n",
    "## 베스트 모델 업데이트하기 - 자동 중단, 그래프로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "df_pre = pd.read_csv('../dataset/wine.csv', header=None)\n",
    "df = df_pre.sample(frac=1)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(30, input_dim=12, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"final{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.18106, saving model to ./model/final001-2.1811.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.18106 to 1.25395, saving model to ./model/final002-1.2539.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25395 to 0.56431, saving model to ./model/final003-0.5643.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56431 to 0.41243, saving model to ./model/final004-0.4124.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41243 to 0.36086, saving model to ./model/final005-0.3609.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36086 to 0.30324, saving model to ./model/final006-0.3032.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30324 to 0.27234, saving model to ./model/final007-0.2723.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27234 to 0.25863, saving model to ./model/final008-0.2586.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25863 to 0.25153, saving model to ./model/final009-0.2515.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.25153 to 0.24671, saving model to ./model/final010-0.2467.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.24671 to 0.24256, saving model to ./model/final011-0.2426.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.24256 to 0.23902, saving model to ./model/final012-0.2390.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.23902 to 0.23558, saving model to ./model/final013-0.2356.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.23558 to 0.23244, saving model to ./model/final014-0.2324.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.23244 to 0.22943, saving model to ./model/final015-0.2294.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22943 to 0.22670, saving model to ./model/final016-0.2267.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22670 to 0.22474, saving model to ./model/final017-0.2247.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22474 to 0.22101, saving model to ./model/final018-0.2210.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22101 to 0.21803, saving model to ./model/final019-0.2180.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21803 to 0.21532, saving model to ./model/final020-0.2153.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.21532 to 0.21278, saving model to ./model/final021-0.2128.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21278 to 0.21097, saving model to ./model/final022-0.2110.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21097 to 0.20804, saving model to ./model/final023-0.2080.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20804 to 0.20655, saving model to ./model/final024-0.2066.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20655 to 0.20374, saving model to ./model/final025-0.2037.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20374 to 0.20177, saving model to ./model/final026-0.2018.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20177 to 0.20116, saving model to ./model/final027-0.2012.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20116 to 0.19912, saving model to ./model/final028-0.1991.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19912 to 0.19720, saving model to ./model/final029-0.1972.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19720 to 0.19524, saving model to ./model/final030-0.1952.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19524 to 0.19330, saving model to ./model/final031-0.1933.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19330 to 0.19201, saving model to ./model/final032-0.1920.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19201 to 0.19005, saving model to ./model/final033-0.1900.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19005 to 0.18867, saving model to ./model/final034-0.1887.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.18867\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18867 to 0.18648, saving model to ./model/final036-0.1865.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18648 to 0.18462, saving model to ./model/final037-0.1846.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.18462\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18462 to 0.18407, saving model to ./model/final039-0.1841.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18407 to 0.18389, saving model to ./model/final040-0.1839.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18389 to 0.18002, saving model to ./model/final041-0.1800.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18002 to 0.17853, saving model to ./model/final042-0.1785.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17853 to 0.17737, saving model to ./model/final043-0.1774.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17737 to 0.17710, saving model to ./model/final044-0.1771.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17710 to 0.17662, saving model to ./model/final045-0.1766.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17662 to 0.17520, saving model to ./model/final046-0.1752.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17520 to 0.17347, saving model to ./model/final047-0.1735.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.17347\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.17347 to 0.17182, saving model to ./model/final049-0.1718.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.17182 to 0.17043, saving model to ./model/final050-0.1704.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.17043 to 0.16909, saving model to ./model/final051-0.1691.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.16909 to 0.16889, saving model to ./model/final052-0.1689.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.16889 to 0.16698, saving model to ./model/final053-0.1670.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.16698 to 0.16618, saving model to ./model/final054-0.1662.hdf5\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.16618 to 0.16548, saving model to ./model/final055-0.1655.hdf5\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.16548\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.16548 to 0.16310, saving model to ./model/final057-0.1631.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.16310\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.16310 to 0.16088, saving model to ./model/final059-0.1609.hdf5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.16088\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.16088\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.16088 to 0.15890, saving model to ./model/final062-0.1589.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.15890 to 0.15830, saving model to ./model/final063-0.1583.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.15830 to 0.15615, saving model to ./model/final064-0.1561.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.15615\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.15615 to 0.15426, saving model to ./model/final066-0.1543.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.15426 to 0.15306, saving model to ./model/final067-0.1531.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.15306\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.15306 to 0.15142, saving model to ./model/final069-0.1514.hdf5\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.15142\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.15142\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.15142 to 0.14983, saving model to ./model/final072-0.1498.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.14983\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.14983 to 0.14894, saving model to ./model/final074-0.1489.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.14894 to 0.14642, saving model to ./model/final075-0.1464.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.14642 to 0.14609, saving model to ./model/final076-0.1461.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.14609 to 0.14457, saving model to ./model/final077-0.1446.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.14457 to 0.14379, saving model to ./model/final078-0.1438.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.14379 to 0.14314, saving model to ./model/final079-0.1431.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.14314 to 0.14227, saving model to ./model/final080-0.1423.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.14227 to 0.14090, saving model to ./model/final081-0.1409.hdf5\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.14090\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.14090\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.14090 to 0.13844, saving model to ./model/final084-0.1384.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.13844\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.13844 to 0.13667, saving model to ./model/final086-0.1367.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.13667 to 0.13592, saving model to ./model/final087-0.1359.hdf5\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.13592 to 0.13556, saving model to ./model/final088-0.1356.hdf5\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.13556 to 0.13509, saving model to ./model/final089-0.1351.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.13509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_loss did not improve from 0.13509\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.13509 to 0.13191, saving model to ./model/final092-0.1319.hdf5\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.13191\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.13191 to 0.13131, saving model to ./model/final094-0.1313.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.13131 to 0.12946, saving model to ./model/final095-0.1295.hdf5\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.12946\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.12946 to 0.12809, saving model to ./model/final097-0.1281.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.12809 to 0.12764, saving model to ./model/final098-0.1276.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.12764 to 0.12625, saving model to ./model/final099-0.1262.hdf5\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.12625 to 0.12534, saving model to ./model/final100-0.1253.hdf5\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.12534\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.12534 to 0.12476, saving model to ./model/final102-0.1248.hdf5\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.12476 to 0.12408, saving model to ./model/final103-0.1241.hdf5\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.12408 to 0.12369, saving model to ./model/final104-0.1237.hdf5\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.12369\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.12369 to 0.12090, saving model to ./model/final106-0.1209.hdf5\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.12090\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.12090 to 0.12030, saving model to ./model/final108-0.1203.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.12030 to 0.11952, saving model to ./model/final109-0.1195.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.11952 to 0.11821, saving model to ./model/final110-0.1182.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.11821 to 0.11759, saving model to ./model/final111-0.1176.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.11759 to 0.11723, saving model to ./model/final112-0.1172.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.11723 to 0.11615, saving model to ./model/final113-0.1162.hdf5\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.11615 to 0.11523, saving model to ./model/final114-0.1152.hdf5\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.11523 to 0.11478, saving model to ./model/final115-0.1148.hdf5\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.11478 to 0.11435, saving model to ./model/final116-0.1144.hdf5\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.11435\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.11435 to 0.11401, saving model to ./model/final118-0.1140.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.11401 to 0.11311, saving model to ./model/final119-0.1131.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.11311 to 0.11150, saving model to ./model/final120-0.1115.hdf5\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.11150 to 0.11111, saving model to ./model/final121-0.1111.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.11111 to 0.11020, saving model to ./model/final122-0.1102.hdf5\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.11020\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.11020\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.11020 to 0.10876, saving model to ./model/final125-0.1088.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.10876 to 0.10585, saving model to ./model/final129-0.1059.hdf5\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.10585 to 0.10444, saving model to ./model/final134-0.1044.hdf5\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.10444\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.10444 to 0.10165, saving model to ./model/final136-0.1017.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.10165 to 0.10147, saving model to ./model/final137-0.1015.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.10147 to 0.10033, saving model to ./model/final138-0.1003.hdf5\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.10033\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.10033\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.10033 to 0.09894, saving model to ./model/final141-0.0989.hdf5\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.09894\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.09894 to 0.09703, saving model to ./model/final143-0.0970.hdf5\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.09703\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.09703 to 0.09641, saving model to ./model/final145-0.0964.hdf5\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.09641 to 0.09542, saving model to ./model/final153-0.0954.hdf5\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.09542 to 0.09285, saving model to ./model/final154-0.0928.hdf5\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.09285\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.09285 to 0.09160, saving model to ./model/final156-0.0916.hdf5\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.09160 to 0.09036, saving model to ./model/final157-0.0904.hdf5\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.09036 to 0.08800, saving model to ./model/final165-0.0880.hdf5\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.08800 to 0.08706, saving model to ./model/final166-0.0871.hdf5\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.08706 to 0.08684, saving model to ./model/final167-0.0868.hdf5\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.08684\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.08684\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.08684 to 0.08550, saving model to ./model/final170-0.0855.hdf5\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.08550\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.08550\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.08550 to 0.08457, saving model to ./model/final173-0.0846.hdf5\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.08457 to 0.08448, saving model to ./model/final179-0.0845.hdf5\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.08448 to 0.08352, saving model to ./model/final180-0.0835.hdf5\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.08352 to 0.08257, saving model to ./model/final181-0.0826.hdf5\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.08257 to 0.08111, saving model to ./model/final182-0.0811.hdf5\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.08111\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.08111\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.08111\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.08111 to 0.08089, saving model to ./model/final186-0.0809.hdf5\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.08089 to 0.07968, saving model to ./model/final187-0.0797.hdf5\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.07968 to 0.07946, saving model to ./model/final188-0.0795.hdf5\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.07946\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.07946 to 0.07914, saving model to ./model/final190-0.0791.hdf5\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.07914 to 0.07856, saving model to ./model/final191-0.0786.hdf5\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.07856\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.07856\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.07856\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.07856 to 0.07750, saving model to ./model/final195-0.0775.hdf5\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.07750 to 0.07739, saving model to ./model/final196-0.0774.hdf5\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.07739\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.07739 to 0.07720, saving model to ./model/final198-0.0772.hdf5\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.07720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00200: val_loss did not improve from 0.07720\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.07720 to 0.07651, saving model to ./model/final201-0.0765.hdf5\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.07651 to 0.07536, saving model to ./model/final206-0.0754.hdf5\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.07536\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.07536 to 0.07515, saving model to ./model/final208-0.0752.hdf5\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.07515\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.07515 to 0.07497, saving model to ./model/final210-0.0750.hdf5\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.07497\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.07497 to 0.07379, saving model to ./model/final212-0.0738.hdf5\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.07379 to 0.07323, saving model to ./model/final213-0.0732.hdf5\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.07323 to 0.07313, saving model to ./model/final214-0.0731.hdf5\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.07313 to 0.07206, saving model to ./model/final220-0.0721.hdf5\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.07206 to 0.07072, saving model to ./model/final225-0.0707.hdf5\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.07072\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.07072\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.07072 to 0.07054, saving model to ./model/final228-0.0705.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.07054 to 0.07032, saving model to ./model/final229-0.0703.hdf5\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.07032\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.07032 to 0.06994, saving model to ./model/final231-0.0699.hdf5\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.06994 to 0.06981, saving model to ./model/final241-0.0698.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.06981 to 0.06865, saving model to ./model/final242-0.0687.hdf5\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.06865 to 0.06830, saving model to ./model/final243-0.0683.hdf5\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.06830 to 0.06813, saving model to ./model/final248-0.0681.hdf5\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.06813\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.06813\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.06813\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.06813 to 0.06786, saving model to ./model/final252-0.0679.hdf5\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.06786 to 0.06696, saving model to ./model/final253-0.0670.hdf5\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.06696 to 0.06690, saving model to ./model/final254-0.0669.hdf5\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.06690 to 0.06672, saving model to ./model/final257-0.0667.hdf5\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.06672 to 0.06616, saving model to ./model/final258-0.0662.hdf5\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.06616 to 0.06580, saving model to ./model/final274-0.0658.hdf5\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.06580 to 0.06495, saving model to ./model/final281-0.0650.hdf5\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.06495 to 0.06397, saving model to ./model/final295-0.0640.hdf5\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.06397 to 0.06385, saving model to ./model/final301-0.0638.hdf5\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.06385 to 0.06381, saving model to ./model/final309-0.0638.hdf5\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.06381 to 0.06347, saving model to ./model/final314-0.0635.hdf5\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.06347\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.06347 to 0.06323, saving model to ./model/final316-0.0632.hdf5\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.06323 to 0.06259, saving model to ./model/final321-0.0626.hdf5\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.06259 to 0.06238, saving model to ./model/final340-0.0624.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00341: val_loss improved from 0.06238 to 0.06220, saving model to ./model/final341-0.0622.hdf5\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.06220 to 0.06174, saving model to ./model/final359-0.0617.hdf5\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.06174 to 0.06167, saving model to ./model/final387-0.0617.hdf5\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.06167 to 0.06167, saving model to ./model/final396-0.0617.hdf5\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.06167 to 0.06151, saving model to ./model/final398-0.0615.hdf5\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00417: val_loss improved from 0.06151 to 0.06124, saving model to ./model/final417-0.0612.hdf5\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.06124 to 0.06122, saving model to ./model/final431-0.0612.hdf5\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.06122 to 0.06116, saving model to ./model/final435-0.0612.hdf5\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.06116\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.06116\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.06116\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.06116 to 0.06071, saving model to ./model/final439-0.0607.hdf5\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.06071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00494: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00529: val_loss improved from 0.06071 to 0.06064, saving model to ./model/final529-0.0606.hdf5\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.06064\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 - 0s - loss: 0.0483 - accuracy: 0.9886\n",
      "\n",
      " Accuracy: 0.9886\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/final529-0.0606.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.ylim((0,1))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
