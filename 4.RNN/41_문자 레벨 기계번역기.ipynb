{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문자 레벨 기계번역기\n",
    "### 참조: [sequence-to-sequence 10분만에 이해하기](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
    "### 다운로드: [프랑스-영어 병렬 코퍼스](http://www.manythings.org/anki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177210"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines = pd.read_csv('data/fra.txt', names=['src', 'dst', 'desc'], sep='\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47455</th>\n",
       "      <td>He left Japan for good.</td>\n",
       "      <td>Il a quitté le Japon pour de bon.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>Do you get it?</td>\n",
       "      <td>Vous pigez ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4583</th>\n",
       "      <td>We need help.</td>\n",
       "      <td>Nous avons besoin d'aide.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>It's not fair.</td>\n",
       "      <td>Ce n'est pas équitable.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54967</th>\n",
       "      <td>I hate people like that.</td>\n",
       "      <td>Je déteste les gens comme ça.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            src                                dst  \\\n",
       "47455   He left Japan for good.  Il a quitté le Japon pour de bon.   \n",
       "5011             Do you get it?                       Vous pigez ?   \n",
       "4583              We need help.          Nous avons besoin d'aide.   \n",
       "6147             It's not fair.            Ce n'est pas équitable.   \n",
       "54967  I hate people like that.      Je déteste les gens comme ça.   \n",
       "\n",
       "                                                    desc  \n",
       "47455  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "5011   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "4583   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "6147   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "54967  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60,000개의 샘플만 가지고 기계 번역기를 구축\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc 컬럼 삭제\n",
    "del lines['desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41548</th>\n",
       "      <td>I didn't feel a thing.</td>\n",
       "      <td>\\t Je n'ai rien ressenti. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32419</th>\n",
       "      <td>Tom's tie is yellow.</td>\n",
       "      <td>\\t La cravate de Tom est jaune. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Let him go.</td>\n",
       "      <td>\\t Laissez-le s'en aller! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13154</th>\n",
       "      <td>What's up, dude?</td>\n",
       "      <td>\\t Comment ça va, mec ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36527</th>\n",
       "      <td>I'm ready if you are.</td>\n",
       "      <td>\\t Je suis prêt si vous l'êtes. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                                 dst\n",
       "41548  I didn't feel a thing.        \\t Je n'ai rien ressenti. \\n\n",
       "32419    Tom's tie is yellow.  \\t La cravate de Tom est jaune. \\n\n",
       "1560              Let him go.        \\t Laissez-le s'en aller! \\n\n",
       "13154        What's up, dude?          \\t Comment ça va, mec ? \\n\n",
       "36527   I'm ready if you are.  \\t Je suis prêt si vous l'êtes. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dst 열에 <sos>로 \\t, <eos>로 \\n 을 추가\n",
    "lines.dst = lines.dst.apply(lambda x : '\\t ' + x + ' \\n')\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글자 집합 생성 (단어가 아님), 즉 토큰 단위가 단어가 아닌 글자\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "dst_vocab = set()\n",
    "for line in lines.dst:\n",
    "    for char in line:\n",
    "        dst_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 105\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "dst_vocab_size = len(dst_vocab)+1\n",
    "print(src_vocab_size, dst_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "dst_vocab = sorted(list(dst_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(dst_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, '?': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, 'С': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "# 각 글자에 인덱스 부여\n",
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "dst_to_index = dict([(word, i+1) for i, word in enumerate(dst_vocab)])\n",
    "print(src_to_index)\n",
    "print(dst_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [31, 58, 10], [31, 58, 10], [41, 70, 63, 2], [41, 70, 63, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 영어 데이터에 대한 정수 인코딩\n",
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "        temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 47, 52, 3, 4, 3, 2], [1, 3, 44, 52, 63, 72, 71, 3, 4, 3, 2], [1, 3, 44, 52, 63, 72, 71, 13, 3, 2], [1, 3, 28, 66, 72, 69, 70, 104, 4, 3, 2], [1, 3, 28, 66, 72, 69, 56, 77, 104, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 프랑스어 데이터에 대한 정수 인코딩\n",
    "decoder_input = []\n",
    "for line in lines.dst:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        temp_X.append(dst_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 47, 52, 3, 4, 3, 2], [3, 44, 52, 63, 72, 71, 3, 4, 3, 2], [3, 44, 52, 63, 72, 71, 13, 3, 2], [3, 28, 66, 72, 69, 70, 104, 4, 3, 2], [3, 28, 66, 72, 69, 56, 77, 104, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 예측값과 비교하기 위한 실제값\n",
    "# 정수 인코딩 과정에서 <sos>를 제거\n",
    "decoder_target = []\n",
    "for line in lines.dst:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "        if t>0:\n",
    "            temp_X.append(dst_to_index[w])\n",
    "        t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 76\n"
     ]
    }
   ],
   "source": [
    "# 패딩을 위해서 영어 문장과 프랑스어 문장 각각에 대해서 가장 길이가 긴 샘플의 길이 확인\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_dst_len = max([len(line) for line in lines.dst])\n",
    "print(max_src_len, max_dst_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 문장의 평균 길이 : 19.27035\n",
      "불어 문장의 평균 길이 : 28.3092\n"
     ]
    }
   ],
   "source": [
    "# 평균 샘플 길이\n",
    "print('영어 문장의 평균 길이 : {}'.format(sum(map(len, lines.src))/len(lines.src)))\n",
    "print('불어 문장의 평균 길이 : {}'.format(sum(map(len, lines.dst))/len(lines.dst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩시 사용할 크기\n",
    "pad_src_len = 25\n",
    "pad_dst_len = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=pad_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=pad_dst_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=pad_dst_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "from keras.utils import to_categorical\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 교사 강요(Teacher forcing)\n",
    "- 훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고,\n",
    "- 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용\n",
    "- RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. seq2seq 기계 번역기 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size), name='Encoder_Input')\n",
    "encoder_lstm = LSTM(units=256, return_state=True, name='Encoder_LSTM')\n",
    "# 인코더의 내부 상태를 디코더로 넘겨주어야 하기 때문에 return_state=True로 설정\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태.\n",
    "# 이겻이 컨텍스트 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, dst_vocab_size), name='Decoder_Input')\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True, \n",
    "                    name='Decoder_LSTM')\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Input (InputLayer)      (None, None, 79)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Input (InputLayer)      (None, None, 105)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM (LSTM)             [(None, 256), (None, 344064      Encoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 256),  370688      Decoder_Input[0][0]              \n",
      "                                                                 Encoder_LSTM[0][1]               \n",
      "                                                                 Encoder_LSTM[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 105)    26985       Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 741,737\n",
      "Trainable params: 741,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_softmax_layer = Dense(dst_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, 'image/seq2seq.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "modelpath = \"model/seq2seq-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "#early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 276s 6ms/step - loss: 0.7605 - val_loss: 0.6840\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68405, saving model to model/seq2seq-01-0.6840.hdf5\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 233s 5ms/step - loss: 0.4848 - val_loss: 0.5660\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68405 to 0.56600, saving model to model/seq2seq-02-0.5660.hdf5\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 319s 7ms/step - loss: 0.4056 - val_loss: 0.4903\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56600 to 0.49030, saving model to model/seq2seq-03-0.4903.hdf5\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 319s 7ms/step - loss: 0.3588 - val_loss: 0.4495\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49030 to 0.44951, saving model to model/seq2seq-04-0.4495.hdf5\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 320s 7ms/step - loss: 0.3280 - val_loss: 0.4248\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44951 to 0.42480, saving model to model/seq2seq-05-0.4248.hdf5\n",
      "Epoch 6/50\n",
      "37120/48000 [======================>.......] - ETA: 1:06 - loss: 0.3078"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-0cec4584f327>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n",
    "          batch_size=64, epochs=50, validation_split=0.2,\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. seq2seq 기계 번역기 동작시키기\n",
    "- 학습한 최종 모델로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태를 이전 상태로 사용\n",
    "decoder_states = [state_h, state_c]\n",
    "# 이번에는 훈련 과정에서와 달리 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict(\n",
    "    (i, char) for char, i in src_to_index.items())\n",
    "index_to_dst = dict(\n",
    "    (i, char) for char, i in dst_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, dst_vocab_size))\n",
    "    target_seq[0, 0, dst_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition: #stop_condition이 True가 될 때까지 루프 반복\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_dst[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <sos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_dst_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트 합니다.\n",
    "        target_seq = np.zeros((1, 1, dst_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  Courez ! \n",
      "-----------------------------------\n",
      "입력 문장: I lost.\n",
      "정답 문장:  J'ai perdu. \n",
      "번역기가 번역한 문장:  J'ai perdu. \n",
      "-----------------------------------\n",
      "입력 문장: Come in.\n",
      "정답 문장:  Entre ! \n",
      "번역기가 번역한 문장:  Entrez ! \n",
      "-----------------------------------\n",
      "입력 문장: I got it.\n",
      "정답 문장:  J'ai capté. \n",
      "번역기가 번역한 문장:  Je l'ai confectionné. \n",
      "-----------------------------------\n",
      "입력 문장: Who cares?\n",
      "정답 문장:  Qui s'en préoccupe ? \n",
      "번역기가 번역한 문장:  Qui s'en soucie ? \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.dst[seq_index][1:len(lines.dst[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. seq2seq 기계 번역기 동작시키기\n",
    "- Best 모델로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model 선택\n",
    "from keras.models import load_model\n",
    "del model\n",
    "model = load_model('model/seq2seq-16-0.3650.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태를 이전 상태로 사용\n",
    "decoder_states = [state_h, state_c]\n",
    "# 이번에는 훈련 과정에서와 달리 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  Courez ! \n",
      "-----------------------------------\n",
      "입력 문장: I lost.\n",
      "정답 문장:  J'ai perdu. \n",
      "번역기가 번역한 문장:  J'ai perdu. \n",
      "-----------------------------------\n",
      "입력 문장: Come in.\n",
      "정답 문장:  Entre ! \n",
      "번역기가 번역한 문장:  Entrez ! \n",
      "-----------------------------------\n",
      "입력 문장: I got it.\n",
      "정답 문장:  J'ai capté. \n",
      "번역기가 번역한 문장:  Je l'ai confectionné. \n",
      "-----------------------------------\n",
      "입력 문장: Who cares?\n",
      "정답 문장:  Qui s'en préoccupe ? \n",
      "번역기가 번역한 문장:  Qui s'en soucie ? \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.dst[seq_index][1:len(lines.dst[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
